---
title: "Banana Experiment"
author: "Peiyao Cai, Jia Guo, Jiatong Liang"
date: "2024-10-28"
output:
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
header-includes:
    - \usepackage{placeins}
---

```{r, echo=FALSE, message=FALSE, results='hide'}
library(dplyr)
library(tidyr)
library(ggplot2)
library(readxl)
library(tidyverse)
```

# Introduction

Many people feel frustrated by overripe bananas, especially when they ripen too quickly, leading to waste and undesirable texture changes. This experiment addresses a common household problem: finding simple ways to slow the ripening process of bananas. By exploring the effects of common preservatives, this study aims to offer a practical solution for households. Specifically, it examines whether accessible items like iodized salt and granulated sugar, known for their preservative properties, can help extend banana freshness.

The experiment centers on whether burying a banana in iodized salt or granulated sugar can slow its ripening. Both salt and sugar are widely used as natural preservatives for their ability to reduce microbial growth and delay food spoilage. By testing these substances on bananas, the experiment seeks to identify a low-cost way to prolong shelf life, thereby reducing food waste.

While iodized salt was chosen for its accessibility, it may not preserve as effectively as specialized salts. Preservation salts, like canning or pickling salt, lack the iodine or anti-caking agents added to table salt. Though these additives are harmless in cooking, they may limit the moisture-drawing effect of different types of salt, which is crucial for slowing decay. Using iodized salt reflects a typical household approach, though its preservative effect may be weaker than that of canning salt and this will be discussed in the conclusion of the report.

# Experiment Overview

This experiment assessed the effects of common household preservatives, iodized salt and granulated sugar, on the ripening process of bananas. The design included two treatment groups, in which bananas were buried in either salt or sugar, and one control group in which no treatment was applied. Both iodized salt and granulated sugar were sourced from Meijer to ensure consistent product quality across treatments.

Thirty bananas were obtained from Kroger and randomly divided in a 1:1:1 ratio among the salt, sugar, and control groups. In order to avoid selection bias, a third party (brother of group member Kevin) purchased the bananas independently, ensuring that group members had no influence over their selection. The third party was not informed about any details involving the experiment. This setup aimed to provide an unbiased comparison across treatment and control groups.

Each banana was photographed and rated every 24 hours, allowing for consistent tracking of color changes as the primary indicator of ripening. These observations were conducted over five days, capturing the progression of ripeness across different treatment conditions. This systematic approach was designed to highlight any delays in ripening due to the preservative effects of salt or sugar compared to untreated bananas.

# Randomization and Blinding

To control for variations in banana size, a randomized block design was used. Each banana was weighed, assigned a number, and placed into one of three size categories: small (142-163 grams), medium (164-190 grams), or large (191-226 grams). Within each block, bananas were randomly assigned to one of the three treatment groups: salt, sugar, or control. This ensured that each group contained 3 small, 4 medium, and 3 large bananas, balancing potential size-related effects on ripening across treatments. 

The experiment was conducted in three covered boxes, each designated for one treatment: one filled with salt, one with sugar, and one left empty as a control. To maintain blinding, the boxes were made visually indistinguishable. A third party (brother of group member Kevin) selected a randomization seed and assigned labels A, B, and C to the boxes, preventing group members from knowing which treatment each box contained. This method provided a double-blind setup, as neither the group members nor the participants responsible for rating could identify the treatment conditions.

Despite initial efforts to maintain a double-blind setup, challenges arose on the first day of the experiment. Distinguishing control bananas from treated ones became unavoidable. Handling the bananas revealed textural differences, as the sugar and salt adhered to the banana skins, making the treatment groups identifiable by touch and appearance. Washing or rubbing off the salt and sugar was avoided to prevent damaging the banana skin, which could interfere with the natural ripening process.

To address these limitations, we implemented adjustments to minimize bias. Although distinguishing between treated and untreated bananas was inevitable, the distinction between the salt and sugar treatments remained less obvious. Consequently, group members refrained from participating in the banana ratings, and instead, external participants were recruited. These participants were kept unaware of the experiment's purpose and methodology. This approach minimized knowledge-based bias, helping to maintain the double-blind intent and ensuring that ratings were based solely on observable ripening.

# Experiment Procedure

Every 24 hours at 9 pm, after sunset, one group member, Jia Guo, took individual pictures of all 30 bananas. The experiment lasted 5 days, from October 17 to October 21, 2024, resulting in a total of 150 pictures. On the first day, labeled "Day 1" in our dataset, we photographed the bananas before treatment to capture their original color. The angle and height of all pictures were kept as consistent as possible, using a 10-inch lamp as a height reference. To prevent contamination from bacteria on our hands, we wore nitrile exam gloves from Costco whenever taking pictures and handling the experiment subjects.

Within the plastic boxes, we did not apply spatial randomization or control for consistent orientation. Due to box size limitations, bananas were placed without touching each other, arranged in a natural, non-randomized layout. We attempted to maintain consistent positions for each banana, but due to the need to bury bananas in sugar and salt, exact placement could not always be identical.

Five participants were recruited to rate the bananas, consisting of the parents and siblings of our group members. Due to Chinese regulations restricting the use of some websites, we could not send emails, use Google Drive, or distribute online surveys. Instead, all ratings were conducted via WeChat, where each member initiated a video call and recorded participant responses with cameras turned off to prevent nonverbal influence. We shared split-screen images of each banana, with one half of the screen displaying the scale and the other half used to browse the 30 banana pictures. All responses and images were recorded and uploaded to our GitHub repository. Each participant rated all 30 bananas daily, and we greatly appreciate their contributions as their involvement was crucial to the experiment.

```{r, banana scale, echo = F, fig.width = 6, fig.height = 4, fig.align = 'center', fig.cap = "Banana color scale used for rating bananas", cache = F}
knitr::include_graphics("images/banana_scale.png")
```

The above figure was the scale we used to rate the bananas. To ensure that the experiment had consistent and reliable responses from the participants, two "dummy" bananas were put additionally into the pictures on days 1, 3, and 5.

```{r dummy_banana, echo = FALSE, fig.align = 'center', fig.cap = "Dummy banana used for ensuring consistency and reliability of responses", out.width = "80%"} 
knitr::include_graphics("images/dummy_banana.png")
``` 

The left banana was a screen shot of banana number 7, the purpose of this banana was to ensure that all participants would accurately evaluate the left picture as a 7 and make sure that they are reading the scale correctly. The right banana was used to ensure consistency, if the banana pictures does not vary across different days, then the participant responses should not vary as well. On all 3 days that these pictures were presented, participants were able to correctly identify the left pictured banana as a 7 and the right picture banana consistently fell into the acceptable range of 6-9 that was decided by the group members. 

```{r, experiment picture, echo = F, fig.width = 6, fig.height = 4, fig.align = 'center', fig.cap = "Picture of the actual experiment setup", cache = F}
knitr::include_graphics("images/experiment_picture.png")
```

```{r, banana 6, echo = F, fig.width = 6, fig.height = 4, fig.align = 'center', fig.cap = "Example of data collection, this is day 1 vs day 5 for banana number 6", cache = F}
knitr::include_graphics("images/banana_6.png")
```

```{r, banana 10, echo = F, fig.width = 6, fig.height = 4, fig.align = 'center', fig.cap = "Example of data collection, this is day 1 vs day 5 for banana number 10", cache = F}
knitr::include_graphics("images/banana_10.png")
```

The above figures show our experiment setup as well as an example of the data. The experiment has 3 buckets with bananas completely buried in the treatment of salt and sugar. The example of the data illustrates how we kept the angle, lighting, white background, and height of the picture consistent from day 1 through day 5. The reasons for doing so will lead us to discuss all of the nuisance and confounder variables that our experiment design tries to control for. Our group thought very deeply about the following variables: temperature, humidity, sunlight exposure, picture lighting, and camera quality. Specifically for camera quality, a majority of cameras have automatic color adjustments and will smoothen features in the photo which creates an effect where a photograph of an object may appear better than how it looks in real life. We wanted to control for all of these variables because we believe that an excellent experiment design should be reproducible and should, to the best of our ability, eliminate all variables that could potentially affect the experiment. The goal is to focus only on the effects of the treatment. 

To control for temperature we set the thermostat to "auto" mode to maintain a consistent 68 degrees Fahrenheit, which is the average room temperature for most homes. There is a belief that higher temperatures can allow a banana to ripen more quickly and in Michigan, the temperature varies drastically throughout the day so we decided to control the temperature in the room. Humidity was set to 40\%, the recommended level for indoor comfort. We eliminated sunlight exposure by keeping the experiment behind a wall that prevents the sunlight from reaching any of the bananas. For picture lighting, we decided that natural light is too inconsistent because it's possible that one day it might rain or be cloudy and the pictures being rated will not be consistent. The experiment will only take place at night and to ensure consistent lighting we decided to use a 60 watt, 4000k cool white lightbulb. Specifically white light was preferred over yellow light because for photography reasons white light can lead to less color auto-adjustments and capture photos "true to life." For camera quality, as Apple promotes better camera features in newer iPhone models, we decided to use the iPhone 14 pro max which was the highest generation among the group. The HDR camera setting was turned off on the iPhone because Apple's support page stated that this was the best way to capture "true to life" photos. One major reason we decided to focus on so many details for this experiment is because we want it to be reproducible. Regardless of where in the world and what time of the year it is, all of these features regarding room condition and camera quality have been controlled and can be replicated with some basic equipment. By having such strict control over all of these variables, we might be limiting the possibility of generalizing these findings of the experiment but we still believe that all of these experimental details are crucial for reproducibility. If there was a lack of control over things like room condition, then the experiment will be difficult to reproduce. 

# Data Analysis

All data is uploaded to the GitHub repository: https://github.com/Jiatong-Liang/STATS604_Project3.git. It includes an experiment diary that describes the data collection process over five days, an Excel sheet with the dataset, and raw photos of the 150 bananas. The dataset records each banana's weight before treatment and includes columns for the five days, each with ratings from five participants.

## Exploratory Data Analysis

```{r, echo=FALSE}
raw =read_xlsx('Info_finfinfin.xlsx')
day1_avg = rowMeans(raw[,5:9])
day5_avg = rowMeans(raw[,25:29])
dif = day5_avg - day1_avg
salt = (raw$Group == 'Salt')
sugar = (raw$Group == 'Sugar')
weight = raw$`Weight1(g)`
data = data.frame(y = dif, salt = as.factor(salt), sugar = as.factor(sugar), weight = weight, day1 = day1_avg)
```

```{r, echo = FALSE}
hist(raw$`Weight1(g)`, main = 'Histogram of Weights', xlab = 'Weights in grams')
```

```{r, echo = FALSE}
#plot1
day2_avg = rowMeans(raw[,10:14])
day3_avg = rowMeans(raw[,15:19])
day4_avg = rowMeans(raw[,20:14])

data_all_day = cbind(day1_avg, day2_avg, day3_avg, day4_avg, day5_avg)
days = 1:5

sugar_sub = data_all_day[which(raw$Group == 'Sugar'),]
salt_sub = data_all_day[which(raw$Group == 'Salt'),]
ctrl_sub = data_all_day[which(raw$Group == 'Control'),]


combined_matrix = rbind(sugar_sub, salt_sub, ctrl_sub)


colors = c(rep("green", 10), rep("red", 10), rep("blue", 10))


matplot(t(combined_matrix), type = "l", lty = 1, col = colors, 
        xlab = "Days", ylab = "Y values", main = "Banana Ripeness Dynamics",lwd = 2)
legend("topleft", legend = c("Sugar", "Salt", "Control"), 
       col = c("green", "red", "blue"), lty = 1)
```

```{r, echo = FALSE}
# Define function to check if there is any decrease in a row from day to day
has_any_decrease <- function(x) any(diff(x) < 0)

# Initialize empty list to store data frames for each replicate that has any decrease
decreasing_replicates <- list()

# Loop through each replicate (1 to 5) to find rows with any decrease across days
for (i in 1:5) {
  # Select columns for the replicate, e.g., Day 1(i), Day 2(i), ..., Day 5(i)
  day_columns <- paste0("Day ", 1:5, "(", i, ")")
  
  # Filter rows where there is any decrease across days
  decreasing_data <- raw %>%
    select(Label, all_of(day_columns)) %>%
    filter(apply(select(., -Label), 1, has_any_decrease)) %>%
    pivot_longer(cols = starts_with("Day"), names_to = "Day", values_to = "Value") %>%
    mutate(Replicate = paste0("Grader ", i))
  
  # Only add to list if there are rows that met the condition
  if (nrow(decreasing_data) > 0) {
    decreasing_replicates[[i]] <- decreasing_data
  }
}

# Check if there is any data to plot
if (length(decreasing_replicates) == 0) {
  message("No rows with any decrease found across the days.")
} else {
  # Combine all decreasing replicates data into a single data frame
  all_decreasing_data <- bind_rows(decreasing_replicates)
  
  # Plot the data with ggplot2
  ggplot(all_decreasing_data, aes(x = Day, y = Value, group = Label, color = Label)) +
    geom_line() +
    geom_point() +
    facet_wrap(~ Replicate) +
    labs(title = "Trends with Any Decrease Across Days for Each Grader",
         y = "Measurement Value",
         color = "Banana identifier") +
    theme_minimal() + theme(
    axis.text.x = element_blank(),    # Remove x-axis text
    axis.ticks.x = element_blank(),   # Remove x-axis ticks
    axis.title.x = element_blank()     # Remove x-axis title
  )
}
```

We examined all cases where graders rated a banana lower on any consecutive days to confirm there was no significant error; no data cleaning was done to remove these entries. The group concluded that these natural human errors were acceptable for the experiment.

```{r, echo = FALSE}
g1_avg = colMeans(raw[,c(5,10,15,20,25)])
g2_avg = colMeans(raw[,(c(5,10,15,20,25)+1)])
g3_avg = colMeans(raw[,(c(5,10,15,20,25)+2)])
g4_avg = colMeans(raw[,(c(5,10,15,20,25)+3)])
g5_avg = colMeans(raw[,(c(5,10,15,20,25)+4)])

combined = rbind(g1_avg,g2_avg,g3_avg,g4_avg,g5_avg)
colors = c('green', 'red', 'blue', 'pink', 'yellow')
matplot(t(combined), type = "l", lty = 1, col = colors, 
        xlab = "Days", ylab = "Y values", main =  "Ripeness Grading Dynamics",lwd = 2)
legend("topleft", legend = c("Grader 1", "Grader 2", "Grader 3", "Grader 4", "Grader 5"), 
       col = c("green", "red", "blue","pink", "yellow"), lty = 1)

```

The first check was to confirm that none of the banana ratings showed an inconsistency in ripening. The overall trend in the figure indicates that ratings increased as expected, with a few bananas showing slight decreases on certain days, which were acceptable human errors. No data entries were removed, and no data cleaning was performed. The second check was for grader bias; if one grader consistently rated bananas higher then this could affect the analysis. The figure shows that, aside from one grader who rated slightly lower on average, the ratings were generally consistent. This allowed us to exclude grader bias from our analysis of treatment effects.

```{r, echo = FALSE}
day2_data <- raw %>%
  select(Label, starts_with("Day")) %>%
  select(Label, ends_with("(1)"))

long_day2_data <- day2_data %>%
  pivot_longer(cols = -Label, names_to = "Day", values_to = "Value") %>%
  mutate(Day = factor(Day, levels = c("Day 1(1)", "Day 2(1)", "Day 3(1)", "Day 4(1)", "Day 5(1)")))

ggplot(long_day2_data, aes(x = Day, y = Value, color = Label, group = Label)) +
  geom_line() +
  geom_point() +
  labs(title = "Measurements for All Labels on Days 1 to 5 (2nd grader)",
       x = "Day",
       y = "Measurement Value",
       color = "Banana identifier") +
  theme_minimal() 
```

We randomly selected one grader from the five and plotted their ratings for all 30 bananas across 5 days. Overall, we observe an expected increasing trend, with occasional decreases in ratings attributed to natural human errors. This pattern appeared consistently across all 5 graders, but only one figure is shown in this report.

## Statistical Tests

```{r, echo = FALSE}
dif_ctrl = dif[which(raw$Group == 'Control')]
dif_salt = dif[which(raw$Group == 'Salt')]
dif_sugar = dif[which(raw$Group == 'Sugar')]

dif_list = list(Control = dif_ctrl, Salt = dif_salt, Sugar = dif_sugar)

boxplot(dif_list,
        main = "Boxplot of Three Groups", 
        xlab = "Groups", 
        ylab = "Difference in Ripeness",
        col = c("lightblue", "lightgreen", "lightpink"))
```

In this section, we examine the treatment effects of burying bananas in sugar and salt and the effect on their ripeness levels. We begin with a simple visualization of our results. We define the response variable $Y$ as the change in ripeness level from day 1 to day 5 for each individual banana. Next, we create box plots for the salt group, sugar group, and control group. As shown in the figure above, the distribution of ripeness levels in the salt group is very similar to that of the control group, while the sugar group appears to have significantly lower ripeness levels than the other two groups. To provide statistical support, we apply a t-test, permutation test, and linear regression to further validate our conclusions.

### T-test

Firstly, we compare the ripeness of the treatment groups (salt or sugar) with the control group using one sided two-sample t-tests. For $t \in \{\mathrm{sugar}, \mathrm{salt}\}$, we focus on the following hypothesis testing problem:
\[
\mathrm{H}_0: \mathrm{Ripeness}_{t} = \mathrm{Ripeness}_{\mathrm{control}},~~\mathrm{versus}~~\mathrm{H}_a: \mathrm{Ripeness}_{t} < \mathrm{Ripeness}_{\mathrm{control}}.
\]
The results are given as follows:
```{r t test, echo = FALSE}
t.test(dif_ctrl, dif_salt, alternative = 'greater')
t.test(dif_ctrl, dif_sugar, alternative  = 'greater')
```

The p-value for the sugar group is very small, supporting our conclusions. 

### Permutation Test

For the permutation test, we focus on the same hypothesis testing problem shown above. 
Considering that each treatment and control group has 20 data points, fully permuting all treatments would require substantial computational resources ($2^{20}$ operations). To address this, we use a blocked permutation test. We group the bananas into three subgroups based on their weights (light, medium, and heavy). Each treatment group contains 10 bananas, with 3 light, 4 medium, and 3 heavy bananas. We then permute only within these weight groups. The testing procedures are outlined below, beginning with the salt group.

```{r, echo = FALSE}
observed_difference = mean(dif_salt) - mean(dif_ctrl)
small_idx = which((raw$size == 'small')&(raw$Group!='Sugar'))
medium_idx = which((raw$size == 'medium')&(raw$Group!='Sugar'))
large_idx = which((raw$size == 'large')&(raw$Group!='Sugar'))

idx_rank = c(small_idx, medium_idx, large_idx)
dif_all = dif[idx_rank]
blockAcombos = combn(6,3)
blockBcombos = combn(8,4)+6
blockCcombos = combn(6,3)+14
blockcombos = matrix(NA, 10, ncol(blockAcombos)*ncol(blockBcombos)*ncol(blockCcombos))
blockcombos[1,] = rep(blockAcombos[1,], each=ncol(blockBcombos)*ncol(blockCcombos))
blockcombos[2,] = rep(blockAcombos[2,], each=ncol(blockBcombos)*ncol(blockCcombos))
blockcombos[3,] = rep(blockAcombos[3,], each=ncol(blockBcombos)*ncol(blockCcombos))
blockcombos[4,] = rep(rep(blockBcombos[1,], each = ncol(blockCcombos)), times = ncol(blockAcombos))
blockcombos[4,] = rep(rep(blockBcombos[1,], each = ncol(blockCcombos)), times = ncol(blockAcombos))
blockcombos[5,] = rep(rep(blockBcombos[2,], each = ncol(blockCcombos)), times = ncol(blockAcombos))
blockcombos[6,] = rep(rep(blockBcombos[3,], each = ncol(blockCcombos)), times = ncol(blockAcombos))
blockcombos[7,] = rep(rep(blockBcombos[4,], each = ncol(blockCcombos)), times = ncol(blockAcombos))
blockcombos[8,] = rep(blockCcombos[1,], times = ncol(blockAcombos) * ncol(blockBcombos))
blockcombos[9,] = rep(blockCcombos[2,], times = ncol(blockAcombos) * ncol(blockBcombos))
blockcombos[10,] = rep(blockCcombos[3,], times = ncol(blockAcombos) * ncol(blockBcombos))

# Permutation test:
combos = blockcombos
permN = ncol(combos)
diffs = rep(NA, permN)
for (i in 1:permN){
permx = rep(0,20)
permx[combos[,i]] = 1
diffs[i] = sum(dif_all[permx==1])/10 - sum(dif_all[permx==0])/10
}
hist(diffs,main='Histogram of difference-in-means (salt group)', xlab='difference-in-means')
print(mean(diffs > observed_difference))
```

The p-value is around $0.2$, which is not significant. Next we consider the sugar group:

```{r, echo = FALSE}
dif_ctrl = dif[which(raw$Group == 'Control')]
dif_salt = dif[which(raw$Group == 'Salt')]
dif_sugar = dif[which(raw$Group == 'Sugar')]

observed_difference = mean(dif_sugar) - mean(dif_ctrl)
small_idx = which((raw$size == 'small')&(raw$Group!='Salt'))
medium_idx = which((raw$size == 'medium')&(raw$Group!='Salt'))
large_idx = which((raw$size == 'large')&(raw$Group!='Salt'))

idx_rank = c(small_idx, medium_idx, large_idx)
dif_all = dif[idx_rank]
blockAcombos = combn(6,3)
blockBcombos = combn(8,4)+6
blockCcombos = combn(6,3)+14
blockcombos = matrix(NA, 10, ncol(blockAcombos)*ncol(blockBcombos)*ncol(blockCcombos))
blockcombos[1,] = rep(blockAcombos[1,], each=ncol(blockBcombos)*ncol(blockCcombos))
blockcombos[2,] = rep(blockAcombos[2,], each=ncol(blockBcombos)*ncol(blockCcombos))
blockcombos[3,] = rep(blockAcombos[3,], each=ncol(blockBcombos)*ncol(blockCcombos))
blockcombos[4,] = rep(rep(blockBcombos[1,], each = ncol(blockCcombos)), times = ncol(blockAcombos))
blockcombos[4,] = rep(rep(blockBcombos[1,], each = ncol(blockCcombos)), times = ncol(blockAcombos))
blockcombos[5,] = rep(rep(blockBcombos[2,], each = ncol(blockCcombos)), times = ncol(blockAcombos))
blockcombos[6,] = rep(rep(blockBcombos[3,], each = ncol(blockCcombos)), times = ncol(blockAcombos))
blockcombos[7,] = rep(rep(blockBcombos[4,], each = ncol(blockCcombos)), times = ncol(blockAcombos))
blockcombos[8,] = rep(blockCcombos[1,], times = ncol(blockAcombos) * ncol(blockBcombos))
blockcombos[9,] = rep(blockCcombos[2,], times = ncol(blockAcombos) * ncol(blockBcombos))
blockcombos[10,] = rep(blockCcombos[3,], times = ncol(blockAcombos) * ncol(blockBcombos))

# Permutation test:
combos = blockcombos
permN = ncol(combos)
diffs = rep(NA, permN)
for (i in 1:permN){
  #print(i)
  permx = rep(0,20)
  permx[combos[,i]] = 1
  diffs[i] = mean(dif_all[permx==1]) - mean(dif_all[permx==0])
}
hist(diffs, main='Histogram of difference-in-means (sugar group)', xlab='difference-in-means')
mean(diffs <= observed_difference)
```

We have a tiny p-value that is less than 0.05, so we can conclude that sugar has an effect in slowing the ripening process, hence supporting our claim.

### Linear Regression Model

Finally, we consider the linear regression model
\[
\mathrm{Ripeness}_i = a + b*\mathrm{weight}_i + c*1\{\mathrm{salt}_i \} + d*1\{\mathrm{sugar}_i \} + e*\mathrm{day1RipenLevel_i} + \epsilon_i
\].
The linear regression result is shown below:

```{r regression, echo = FALSE}
lm_obj = lm(y~., data = data)
summary(lm_obj)
```

The purpose of the linear regression model is to adjust for the Day 1 colors and the weight as baseline covariates. We can see that the sugar indicator is significantly negative in the regression result with a small p value. Putting all pieces together, our statistical test results together show that burying bananas in sugar can slow down banana ripeness.

# Conclusion

Overall, our findings suggest that burying bananas in granulated sugar slows the ripening process, while iodized salt is ineffective. A possible improvement to this experiment would be to use canning salt instead of iodized salt. Before this experiment, we did not realize that not all salts are preservatives. In fact, iodized salt is not recommended for pickling and canning salt is typically used to preserve food.
